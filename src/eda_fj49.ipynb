{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        NaN   \n",
       "1                       -1         0.999896    1642214.25        NaN   \n",
       "2                       -1         0.999561    1819368.03        NaN   \n",
       "3                       -1         1.000171   18389745.62        NaN   \n",
       "4                       -1         0.999532   17860614.95        NaN   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         NaN   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         NaN   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         NaN   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         NaN   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         NaN   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0075966 ,  0.06851923, -1.01702748, ..., -0.4366326 ,\n",
       "        2.46220483, -0.99759714])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression model with outcome variable being target\n",
    "#write it man\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Assuming df is your DataFrame and it includes a 'target' column\n",
    "X = train.drop('target', axis=1)  # feature columns\n",
    "y = train['target']  # target column\n",
    "\n",
    "\n",
    "#can u remove the NaNs\n",
    "X = X.fillna(0)\n",
    "y = y.fillna(0)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Now the model is trained and you can use model.predict() to make predictions\n",
    "\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best features are:  ['bid_size']\n",
      "The best features are:  ['imbalance_buy_sell_flag', 'bid_size']\n",
      "The best features are:  ['imbalance_buy_sell_flag', 'bid_size', 'ask_size']\n",
      "The best features are:  ['imbalance_buy_sell_flag', 'bid_size', 'ask_size', 'wap']\n",
      "The best features are:  ['imbalance_buy_sell_flag', 'bid_price', 'bid_size', 'ask_size', 'wap']\n",
      "The best features are:  ['imbalance_buy_sell_flag', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
      "The best features are:  ['imbalance_buy_sell_flag', 'reference_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
      "The best features are:  ['seconds_in_bucket', 'imbalance_buy_sell_flag', 'reference_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
      "The best features are:  ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
      "The best features are:  ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
      "The best features are:  ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'row_id']\n",
      "The best features are:  ['date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'row_id']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Assuming X is your feature set and y is the target variable\n",
    "for i in range (1,13):\n",
    "    selector = SelectKBest(f_regression, k=i)\n",
    "\n",
    "    # Fit transform the data\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "\n",
    "    # Get the feature names\n",
    "    mask = selector.get_support()  # list of booleans for selected features\n",
    "    new_features = []  # The list of your K best features\n",
    "\n",
    "    for bool, feature in zip(mask, X.columns):\n",
    "        if bool:\n",
    "            new_features.append(feature)\n",
    "\n",
    "    print('The best features are: ', new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1 = ['bid_size']\n",
    "top2 =  ['imbalance_buy_sell_flag', 'bid_size']\n",
    "top3 =   ['imbalance_buy_sell_flag', 'bid_size', 'ask_size']\n",
    "top4 =   ['imbalance_buy_sell_flag', 'bid_size', 'ask_size', 'wap']\n",
    "top5 =   ['imbalance_buy_sell_flag', 'bid_price', 'bid_size', 'ask_size', 'wap']\n",
    "top6 =   ['imbalance_buy_sell_flag', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
    "top7 =   ['imbalance_buy_sell_flag', 'reference_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
    "top8 =   ['seconds_in_bucket', 'imbalance_buy_sell_flag', 'reference_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
    "top9 =   ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
    "top10 =  ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap']\n",
    "top11 =  ['seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'row_id']\n",
    "top12 =  ['date_id', 'seconds_in_bucket', 'imbalance_size', 'imbalance_buy_sell_flag', 'reference_price', 'near_price', 'bid_price', 'bid_size', 'ask_price', 'ask_size', 'wap', 'row_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.326734832854248"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAE when all features r used\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for top 1 features is 6.4108363083142725\n",
      "MAE for top 2 features is 6.410141069526442\n",
      "MAE for top 3 features is 6.407456181293434\n",
      "MAE for top 4 features is 6.406910213884661\n",
      "MAE for top 5 features is 6.383517860414299\n",
      "MAE for top 6 features is 6.332886774866157\n",
      "MAE for top 7 features is 6.327004219261476\n",
      "MAE for top 8 features is 6.326974768047381\n",
      "MAE for top 9 features is 6.326986918746517\n",
      "MAE for top 10 features is 6.326753569743947\n",
      "MAE for top 11 features is 6.326752152282785\n",
      "MAE for top 12 features is 6.326753615837946\n"
     ]
    }
   ],
   "source": [
    "#runnning regression on all top 12 features\n",
    "tops = [top1, top2, top3, top4, top5, top6, top7, top8, top9, top10, top11, top12]\n",
    "\n",
    "for i in range (0,12):\n",
    "    X = train[tops[i]]  # feature columns\n",
    "    y = train['target']  # target column\n",
    "\n",
    "\n",
    "    #can u remove the NaNs\n",
    "    X = X.fillna(0)\n",
    "    y = y.fillna(0)\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create a linear regression model\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Now the model is trained and you can use model.predict() to make predictions\n",
    "\n",
    "    model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, model.predict(X_test))\n",
    "\n",
    "    print('MAE for top', i+1, 'features is', mae)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bid_size']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops = [top1, top2, top3, top4, top5, top6, top7, top8, top9, top10, top11, top12]\n",
    "a = train[tops[2]]\n",
    "top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mae for random forest is 6.4095719408404\n"
     ]
    }
   ],
   "source": [
    "#try another model now for the data\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X = train[['ask_price', 'wap']]  # feature columns\n",
    "y = train['target']  # target column\n",
    "\n",
    "#can u remove the NaNs\n",
    "X = X.fillna(0)\n",
    "y = y.fillna(0)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=10, max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.predict(X_test)\n",
    "mean_absolute_error(y_test, clf.predict(X_test))\n",
    "\n",
    "print (\"Mae for random forest is\", mean_absolute_error(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18206414 0.81793586]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['stock_id', 'date_id', 'seconds_in_bucket', 'imbalance_size',\n",
       "       'imbalance_buy_sell_flag', 'reference_price', 'matched_size',\n",
       "       'far_price', 'near_price', 'bid_price', 'bid_size', 'ask_price',\n",
       "       'ask_size', 'wap', 'target', 'time_id', 'row_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top features for random forest\n",
    "importances = clf.feature_importances_\n",
    "print (importances)\n",
    "\n",
    "#how do i know what feature is the vector referring to\n",
    "\n",
    "train.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on some domain knowledge and some research and reading a few threads on kaggle, did some feature engineering\n",
    "\n",
    "#liquidity imbalance\n",
    "train['liquidity_imbalance'] = (train['ask_size'] - train['bid_size']) / (train['ask_size'] + train['bid_size'])\n",
    "\n",
    "#matched imbalance\n",
    "train['matched_imbalance'] = (train['imbalance_size']-train['matched_size'])/ (train['matched_size']+train['imbalance_size'])\n",
    "\n",
    "#spread\n",
    "train['spread'] = train['ask_price'] - train['bid_price']\n",
    "\n",
    "#mid price - might be close to what the stock is traded (if less liquidity)\n",
    "train['mid_price'] = (train['ask_price'] + train['bid_price'])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=[\"target\"])\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in ['row_id', 'time_id', 'target']]\n",
    "X = train[features].copy(deep=True)\n",
    "y = train['target'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also creating a Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5138892, 18), (99000, 18), (5138892,), (99000,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_days = len(X.date_id.unique()) # There are 481 trading days, we'll take the last n as testing set\n",
    "testing_days = 10\n",
    "training_days = number_of_days - testing_days\n",
    "training_days, testing_days\n",
    "\n",
    "# mask to grab the days for training and testing\n",
    "training_mask = X.date_id <= training_days\n",
    "testing_mask = X.date_id > training_days\n",
    "\n",
    "# subset and make training and validation sets\n",
    "X_train, X_val, y_train, y_val = X[training_mask], X[testing_mask], y[training_mask], y[testing_mask] #train_test_split(X, y, test_size=0.20, random_state=0, shuffle=True, stratify=X['stock_id']) # random_state=8\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from catboost import EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "from catboost import Pool\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool = Pool(data=X_train, label=y_train)# , cat_features=cat_features) # , cat_features=cat_features\n",
    "val_pool = Pool(data=X_val, label=y_val)#, cat_features=cat_features) # , cat_features=cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(loss_function ='MAE',\n",
    "              eval_metric= \"MAE\",\n",
    "              metric_period = 100,\n",
    "              bootstrap_type = \"Bernoulli\",\n",
    "              od_type = 'Iter',\n",
    "              od_wait = 20,\n",
    "              border_count = 32,\n",
    "              #use_best_model = True,\n",
    "              task_type = 'GPU',\n",
    "              random_seed=7,\n",
    "              iterations = 600,\n",
    "              subsample=0.779472827911377,\n",
    "              random_strength=11.285714149475098, # more bagging to reduce overfitting\n",
    "              depth=8,\n",
    "              l2_leaf_reg=33,\n",
    "              learning_rate=0.012735510244965552,\n",
    "              )\n",
    "\n",
    "\n",
    "model = CatBoostRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss_function': 'MAE', 'eval_metric': 'MAE', 'metric_period': 100, 'bootstrap_type': 'Bernoulli', 'od_type': 'Iter', 'od_wait': 20, 'border_count': 32, 'task_type': 'GPU', 'random_seed': 7, 'iterations': 600, 'subsample': 0.779472827911377, 'random_strength': 11.285714149475098, 'depth': 8, 'l2_leaf_reg': 33, 'learning_rate': 0.012735510244965552}\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "/src/catboost/catboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 35: CUDA driver version is insufficient for CUDA runtime version",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bglorious-enigma-q5x4qqvv6jjf44x5/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(final_params)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bglorious-enigma-q5x4qqvv6jjf44x5/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m final_model \u001b[39m=\u001b[39m CatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfinal_params)\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bglorious-enigma-q5x4qqvv6jjf44x5/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m final_model\u001b[39m.\u001b[39;49mfit(X_train, \u001b[39m#[summary['selected_features_names']],  # \u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bglorious-enigma-q5x4qqvv6jjf44x5/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m                 y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bglorious-enigma-q5x4qqvv6jjf44x5/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m                 eval_set\u001b[39m=\u001b[39;49m(X_val, y_val)) \u001b[39m# [summary['selected_features_names']]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bglorious-enigma-q5x4qqvv6jjf44x5/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-----Predicting with the reduced set model-----------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bglorious-enigma-q5x4qqvv6jjf44x5/workspaces/NasdaqClosingCross/src/eda_fj49.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m y_val_pred \u001b[39m=\u001b[39m final_model\u001b[39m.\u001b[39mpredict(X_val) \u001b[39m# [summary['selected_features_names']]\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/catboost/core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: /src/catboost/catboost/cuda/cuda_lib/cuda_base.h:281: CUDA error 35: CUDA driver version is insufficient for CUDA runtime version"
     ]
    }
   ],
   "source": [
    "# https://medium.com/analytics-vidhya/catboost-101-fb2fdc3398f3\n",
    "\n",
    "# Retrain the model with the recommended number of iterations and the reduced feature set\n",
    "final_params = params.copy()\n",
    "updates = dict(#score_function='Cosine'\n",
    "              )\n",
    "final_params.update(updates)\n",
    "print(final_params)\n",
    "final_model = CatBoostRegressor(**final_params)\n",
    "final_model.fit(X_train, #[summary['selected_features_names']],  # \n",
    "                y_train,\n",
    "                eval_set=(X_val, y_val)) # [summary['selected_features_names']]\n",
    "\n",
    "print(\"-----Predicting with the reduced set model-----------\")\n",
    "y_val_pred = final_model.predict(X_val) # [summary['selected_features_names']]\n",
    "y_val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "print(f\"MAE on validation set: {np.round(y_val_mae, 4)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
